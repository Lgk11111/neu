import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.model_selection import StratifiedKFold
from sklearn.metrics import classification_report, confusion_matrix
import warnings
import time
from collections import Counter

warnings.filterwarnings('ignore')


# ==================== 1. ç»ˆæé…ç½®å‚æ•° ====================
class Config:
    # è·¯å¾„é…ç½®
    train_dir = './train'
    test_dir = './test'
    submission_file = './submission.csv'

    # æ•°æ®å‚æ•°ï¼ˆå…³é”®ï¼šä½¿ç”¨æ›´å¤§çš„å°ºå¯¸ï¼‰
    img_size = 96  # æ›´å¤§çš„å°ºå¯¸ä¿ç•™æ›´å¤šé¢éƒ¨ç»†èŠ‚
    num_classes = 6
    emotion_map = {0: 'Angry', 1: 'Fear', 2: 'Happy', 3: 'Sad', 4: 'Surprise', 5: 'Neutral'}

    # è®­ç»ƒå‚æ•°ï¼ˆä¼˜åŒ–ï¼‰
    batch_size = 32  # åˆé€‚çš„æ‰¹æ¬¡å¤§å°
    epochs = 40  # è¶³å¤Ÿçš„è®­ç»ƒè½®æ¬¡
    learning_rate = 0.0005  # åˆé€‚çš„å­¦ä¹ ç‡
    weight_decay = 1e-4  # æ­£åˆ™åŒ–

    # è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # é›†æˆå­¦ä¹ é…ç½®
    use_ensemble = True  # ä½¿ç”¨é›†æˆå­¦ä¹ 
    n_models = 3  # è®­ç»ƒ3ä¸ªä¸åŒçš„æ¨¡å‹
    model_names = ['efficientnet_b0', 'resnet34', 'resnet50']  # ä¸åŒçš„æ¨¡å‹æ¶æ„

    # æ•°æ®å¢å¼ºå¼ºåº¦
    augment_strength = 'strong'  # å¼ºæ•°æ®å¢å¼º

    # äº¤å‰éªŒè¯
    use_cv = True
    n_folds = 5

    # æ¨¡å‹ä¿å­˜
    model_save_path = './models/'
    os.makedirs(model_save_path, exist_ok=True)


# ==================== 2. é«˜çº§æ•°æ®é›†ç±»ï¼ˆå¸¦å¼ºæ•°æ®å¢å¼ºï¼‰ ====================
class AdvancedEmotionDataset(Dataset):
    """é«˜çº§æ•°æ®é›†ç±»ï¼Œå¸¦å¤šç§æ•°æ®å¢å¼º"""

    def __init__(self, data_dir=None, image_paths=None, labels=None, is_train=True):
        self.is_train = is_train

        if is_train and data_dir:
            self.image_paths = []
            self.labels = []

            # åŠ è½½æ‰€æœ‰å›¾åƒè·¯å¾„
            for emotion_idx, emotion_name in Config.emotion_map.items():
                emotion_dir = os.path.join(data_dir, emotion_name)
                if os.path.exists(emotion_dir):
                    img_files = [f for f in os.listdir(emotion_dir)
                                 if f.lower().endswith(('.jpg', '.png', '.jpeg'))]

                    for img_file in img_files:
                        self.image_paths.append(os.path.join(emotion_dir, img_file))
                        self.labels.append(emotion_idx)

            print(f"åŠ è½½äº† {len(self.image_paths)} å¼ è®­ç»ƒå›¾åƒ")
            self.show_class_distribution()
        else:
            self.image_paths = image_paths if image_paths else []
            self.labels = labels if labels is not None else [0] * len(self.image_paths)

    def show_class_distribution(self):
        """æ˜¾ç¤ºç±»åˆ«åˆ†å¸ƒ"""
        counter = Counter(self.labels)
        print("\nç±»åˆ«åˆ†å¸ƒç»Ÿè®¡:")
        total = len(self.labels)
        for emotion_id, emotion_name in Config.emotion_map.items():
            count = counter.get(emotion_id, 0)
            if count > 0:
                percentage = count / total * 100
                print(f"  {emotion_name}: {count} ({percentage:.1f}%)")

        # æ£€æŸ¥ç±»åˆ«å¹³è¡¡æ€§
        if total > 0:
            max_count = max(counter.values())
            min_count = min(counter.values())
            imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')
            if imbalance_ratio > 2:
                print(f"\nè­¦å‘Š: æ•°æ®é›†ä¸å¹³è¡¡ (æœ€å¤§/æœ€å° = {imbalance_ratio:.1f})")

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        try:
            img_path = self.image_paths[idx]

            # è¯»å–å›¾åƒ
            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
            if img is None:
                raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {img_path}")

            # è½¬æ¢ä¸ºRGB
            img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)
            img = Image.fromarray(img)

            # åº”ç”¨å˜æ¢
            if self.is_train:
                img = self.strong_train_transform(img)
            else:
                img = self.val_transform(img)

            return img, self.labels[idx], os.path.basename(img_path)

        except Exception as e:
            print(f"å¤„ç†å›¾åƒæ—¶å‡ºé”™: {e}")
            dummy = torch.zeros(3, Config.img_size, Config.img_size)
            return dummy, 0, "error.jpg"

    @property
    def strong_train_transform(self):
        """å¼ºæ•°æ®å¢å¼ºå˜æ¢"""
        if Config.augment_strength == 'strong':
            return transforms.Compose([
                transforms.Resize((Config.img_size + 20, Config.img_size + 20)),  # å…ˆæ”¾å¤§
                transforms.RandomCrop((Config.img_size, Config.img_size)),  # éšæœºè£å‰ª
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomRotation(15),
                transforms.RandomAffine(degrees=0, translate=(0.15, 0.15), scale=(0.85, 1.15)),
                transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2, hue=0.1),
                transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.2),
                transforms.RandomApply([transforms.RandomPerspective(distortion_scale=0.2)], p=0.2),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                     std=[0.229, 0.224, 0.225]),
                transforms.RandomErasing(p=0.3, scale=(0.02, 0.1), ratio=(0.3, 3.3)),
            ])
        else:
            return transforms.Compose([
                transforms.Resize((Config.img_size, Config.img_size)),
                transforms.RandomHorizontalFlip(p=0.5),
                transforms.RandomRotation(10),
                transforms.ColorJitter(brightness=0.2, contrast=0.2),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                     std=[0.229, 0.224, 0.225]),
            ])

    @property
    def val_transform(self):
        """éªŒè¯/æµ‹è¯•å˜æ¢"""
        return transforms.Compose([
            transforms.Resize((Config.img_size, Config.img_size)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225]),
        ])


# ==================== 3. é«˜çº§æ¨¡å‹æ¶æ„ï¼ˆå¸¦æ³¨æ„åŠ›æœºåˆ¶ï¼‰ ====================
class SEBlock(nn.Module):
    """å‹ç¼©-æ¿€å‘æ³¨æ„åŠ›æ¨¡å—"""

    def __init__(self, channel, reduction=16):
        super(SEBlock, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        return x * y.expand_as(x)


class AttentionEmotionModel(nn.Module):
    """å¸¦æ³¨æ„åŠ›çš„æƒ…æ„Ÿåˆ†ç±»æ¨¡å‹"""

    def __init__(self, base_model_name='resnet34', num_classes=6, pretrained=True):
        super(AttentionEmotionModel, self).__init__()

        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        if base_model_name == 'resnet34':
            backbone = models.resnet34(pretrained=pretrained)
            in_features = backbone.fc.in_features
            # ç§»é™¤æœ€åçš„å…¨è¿æ¥å±‚
            self.features = nn.Sequential(*list(backbone.children())[:-2])
            # åœ¨ç‰¹å®šå±‚åæ·»åŠ æ³¨æ„åŠ›
            self.se1 = SEBlock(64)
            self.se2 = SEBlock(128)
            self.se3 = SEBlock(256)
            self.se4 = SEBlock(512)

        elif base_model_name == 'resnet50':
            backbone = models.resnet50(pretrained=pretrained)
            in_features = backbone.fc.in_features
            self.features = nn.Sequential(*list(backbone.children())[:-2])
            self.se1 = SEBlock(64)
            self.se2 = SEBlock(128)
            self.se3 = SEBlock(256)
            self.se4 = SEBlock(512)

        elif base_model_name == 'efficientnet_b0':
            backbone = models.efficientnet_b0(pretrained=pretrained)
            in_features = backbone.classifier[1].in_features
            self.features = backbone.features

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„æ¨¡å‹: {base_model_name}")

        # å…¨å±€å¹³å‡æ± åŒ–
        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))

        # åˆ†ç±»å¤´
        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(in_features, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(inplace=True),
            nn.Dropout(0.2),
            nn.Linear(256, num_classes)
        )

        # åˆå§‹åŒ–æƒé‡
        self._initialize_weights()

    def _initialize_weights(self):
        """åˆå§‹åŒ–åˆ†ç±»å¤´çš„æƒé‡"""
        for m in self.classifier.modules():
            if isinstance(m, nn.Linear):
                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)
            elif isinstance(m, nn.BatchNorm1d):
                nn.init.constant_(m.weight, 1)
                nn.init.constant_(m.bias, 0)

    def forward(self, x):
        x = self.features(x)

        # å¦‚æœæœ‰æ³¨æ„åŠ›æ¨¡å—ï¼Œåº”ç”¨å®ƒä»¬
        if hasattr(self, 'se4'):
            # å¯¹ResNetçš„ç‰¹å¾å›¾åº”ç”¨æ³¨æ„åŠ›
            if x.size(1) == 512:
                x = self.se4(x)
            elif x.size(1) == 256:
                x = self.se3(x)

        x = self.avgpool(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x


# ==================== 4. é«˜çº§è®­ç»ƒç­–ç•¥ ====================
def train_with_cosine_annealing(model, train_loader, val_loader, num_epochs=40, model_name='model'):
    """ä½¿ç”¨Cosineé€€ç«è®­ç»ƒ"""
    print(f"\nè®­ç»ƒ {model_name}...")

    # æŸå¤±å‡½æ•°ï¼ˆå¸¦ç±»åˆ«æƒé‡ï¼‰
    criterion = nn.CrossEntropyLoss()

    # ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(
        model.parameters(),
        lr=Config.learning_rate,
        weight_decay=Config.weight_decay
    )

    # Cosineé€€ç«å­¦ä¹ ç‡è°ƒåº¦
    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
        optimizer,
        T_0=10,  # åˆå§‹å‘¨æœŸ
        T_mult=2,  # å‘¨æœŸå€å¢å› å­
        eta_min=1e-6  # æœ€å°å­¦ä¹ ç‡
    )

    # è®­ç»ƒè®°å½•
    best_acc = 0.0
    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}

    for epoch in range(num_epochs):
        print(f"\nEpoch {epoch + 1}/{num_epochs}")
        print("-" * 40)

        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0

        for batch_idx, (inputs, targets, _) in enumerate(train_loader):
            inputs, targets = inputs.to(Config.device), targets.to(Config.device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()

            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            optimizer.step()

            train_loss += loss.item()
            _, predicted = outputs.max(1)
            train_total += targets.size(0)
            train_correct += predicted.eq(targets).sum().item()

            if (batch_idx + 1) % 30 == 0:
                avg_loss = train_loss / (batch_idx + 1)
                acc = 100. * train_correct / train_total
                print(f'  Batch {batch_idx + 1}/{len(train_loader)} | '
                      f'Loss: {avg_loss:.4f} | Acc: {acc:.2f}%')

        # å­¦ä¹ ç‡è°ƒåº¦
        scheduler.step()

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0

        with torch.no_grad():
            for inputs, targets, _ in val_loader:
                inputs, targets = inputs.to(Config.device), targets.to(Config.device)
                outputs = model(inputs)
                loss = criterion(outputs, targets)

                val_loss += loss.item()
                _, predicted = outputs.max(1)
                val_total += targets.size(0)
                val_correct += predicted.eq(targets).sum().item()

        # è®¡ç®—æŒ‡æ ‡
        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)
        train_acc = 100. * train_correct / train_total
        val_acc = 100. * val_correct / val_total

        # ä¿å­˜å†å²
        history['train_loss'].append(avg_train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(avg_val_loss)
        history['val_acc'].append(val_acc)

        print(f'Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%')
        print(f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%')

        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if val_acc > best_acc:
            best_acc = val_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': val_acc,
                'model_name': model_name,
            }, os.path.join(Config.model_save_path, f'best_{model_name}.pth'))
            print(f'âœ“ ä¿å­˜æœ€ä½³{model_name} | éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%')

    print(f'\n{model_name} æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_acc:.2f}%')
    return best_acc, history


# ==================== 5. äº¤å‰éªŒè¯è®­ç»ƒ ====================
def cross_validation_training():
    """äº¤å‰éªŒè¯è®­ç»ƒ"""
    print("=" * 70)
    print("å¼€å§‹äº¤å‰éªŒè¯è®­ç»ƒ")
    print("=" * 70)

    # åŠ è½½å®Œæ•´æ•°æ®é›†
    dataset = AdvancedEmotionDataset(data_dir=Config.train_dir, is_train=True)

    # å‡†å¤‡æ•°æ®
    X = np.arange(len(dataset))
    y = dataset.labels

    # åˆ†å±‚KæŠ˜äº¤å‰éªŒè¯
    skf = StratifiedKFold(n_splits=Config.n_folds, shuffle=True, random_state=42)

    fold_accuracies = []
    all_histories = []

    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):
        print(f"\n{'=' * 60}")
        print(f"Fold {fold + 1}/{Config.n_folds}")
        print(f"{'=' * 60}")

        # åˆ›å»ºæ•°æ®å­é›†
        train_subset = torch.utils.data.Subset(dataset, train_idx)
        val_subset = torch.utils.data.Subset(dataset, val_idx)

        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_loader = DataLoader(
            train_subset, batch_size=Config.batch_size,
            shuffle=True, num_workers=0
        )
        val_loader = DataLoader(
            val_subset, batch_size=Config.batch_size * 2,
            shuffle=False, num_workers=0
        )

        # åˆ›å»ºæ¨¡å‹
        model = AttentionEmotionModel('resnet34', Config.num_classes, pretrained=True)
        model = model.to(Config.device)

        # è®­ç»ƒ
        best_acc, history = train_with_cosine_annealing(
            model, train_loader, val_loader,
            num_epochs=Config.epochs,
            model_name=f'fold{fold + 1}_resnet34'
        )

        fold_accuracies.append(best_acc)
        all_histories.append(history)

        print(f"\nFold {fold + 1} å®Œæˆ | æœ€ä½³å‡†ç¡®ç‡: {best_acc:.2f}%")

    # æ‰“å°äº¤å‰éªŒè¯ç»“æœ
    print(f"\n{'=' * 70}")
    print("äº¤å‰éªŒè¯ç»“æœ")
    print(f"{'=' * 70}")
    for i, acc in enumerate(fold_accuracies):
        print(f"Fold {i + 1}: {acc:.2f}%")

    mean_acc = np.mean(fold_accuracies)
    std_acc = np.std(fold_accuracies)
    print(f"\nå¹³å‡å‡†ç¡®ç‡: {mean_acc:.2f}% Â± {std_acc:.2f}%")

    return mean_acc


# ==================== 6. é›†æˆå­¦ä¹ è®­ç»ƒ ====================
def ensemble_training():
    """é›†æˆå­¦ä¹ è®­ç»ƒå¤šä¸ªæ¨¡å‹"""
    print("=" * 70)
    print("å¼€å§‹é›†æˆå­¦ä¹ è®­ç»ƒ")
    print("=" * 70)

    # åŠ è½½å®Œæ•´æ•°æ®é›†
    dataset = AdvancedEmotionDataset(data_dir=Config.train_dir, is_train=True)

    # åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
    from sklearn.model_selection import train_test_split
    indices = list(range(len(dataset)))

    train_idx, val_idx = train_test_split(
        indices, test_size=0.2,
        stratify=dataset.labels,
        random_state=42
    )

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_subset = torch.utils.data.Subset(dataset, train_idx)
    val_subset = torch.utils.data.Subset(dataset, val_idx)

    train_loader = DataLoader(
        train_subset, batch_size=Config.batch_size,
        shuffle=True, num_workers=0
    )
    val_loader = DataLoader(
        val_subset, batch_size=Config.batch_size * 2,
        shuffle=False, num_workers=0
    )

    # è®­ç»ƒå¤šä¸ªä¸åŒçš„æ¨¡å‹
    model_accuracies = []

    for i, model_name in enumerate(Config.model_names[:Config.n_models]):
        print(f"\nè®­ç»ƒæ¨¡å‹ {i + 1}/{Config.n_models}: {model_name}")
        print("-" * 50)

        try:
            # åˆ›å»ºæ¨¡å‹
            model = AttentionEmotionModel(model_name, Config.num_classes, pretrained=True)
            model = model.to(Config.device)

            # è®­ç»ƒ
            best_acc, history = train_with_cosine_annealing(
                model, train_loader, val_loader,
                num_epochs=Config.epochs,
                model_name=f'ensemble_{model_name}'
            )

            model_accuracies.append((model_name, best_acc))
            print(f"æ¨¡å‹ {model_name} å®Œæˆ | å‡†ç¡®ç‡: {best_acc:.2f}%")

        except Exception as e:
            print(f"è®­ç»ƒæ¨¡å‹ {model_name} æ—¶å‡ºé”™: {e}")
            # å¦‚æœæŸä¸ªæ¨¡å‹å¤±è´¥ï¼Œä½¿ç”¨å¤‡é€‰æ¨¡å‹
            if model_name != 'resnet34':
                print(f"ä½¿ç”¨ resnet34 ä½œä¸ºæ›¿ä»£")
                model = AttentionEmotionModel('resnet34', Config.num_classes, pretrained=True)
                model = model.to(Config.device)

                best_acc, history = train_with_cosine_annealing(
                    model, train_loader, val_loader,
                    num_epochs=Config.epochs,
                    model_name=f'ensemble_resnet34_alt{i}'
                )

                model_accuracies.append(('resnet34', best_acc))

    # æ‰“å°é›†æˆå­¦ä¹ ç»“æœ
    print(f"\n{'=' * 70}")
    print("é›†æˆå­¦ä¹ ç»“æœ")
    print(f"{'=' * 70}")
    for model_name, acc in model_accuracies:
        print(f"{model_name}: {acc:.2f}%")

    avg_acc = np.mean([acc for _, acc in model_accuracies])
    print(f"\nå¹³å‡å‡†ç¡®ç‡: {avg_acc:.2f}%")

    return avg_acc


# ==================== 7. é›†æˆé¢„æµ‹ ====================
def ensemble_predict():
    """ä½¿ç”¨é›†æˆå­¦ä¹ è¿›è¡Œé¢„æµ‹"""
    print("\n" + "=" * 60)
    print("é›†æˆå­¦ä¹ é¢„æµ‹")
    print("=" * 60)

    # æ£€æŸ¥æµ‹è¯•ç›®å½•
    if not os.path.exists(Config.test_dir):
        print(f"æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {Config.test_dir}")
        return None

    # æ”¶é›†æµ‹è¯•å›¾åƒ
    test_images = []
    test_ids = []

    for img_name in sorted(os.listdir(Config.test_dir)):
        if img_name.lower().endswith(('.jpg', '.png', '.jpeg')):
            test_images.append(os.path.join(Config.test_dir, img_name))
            test_ids.append(img_name)

    if not test_images:
        print("æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒ")
        return None

    print(f"æ‰¾åˆ° {len(test_images)} å¼ æµ‹è¯•å›¾åƒ")

    # åˆ›å»ºæµ‹è¯•æ•°æ®é›†
    test_dataset = AdvancedEmotionDataset(
        image_paths=test_images,
        labels=None,
        is_train=False
    )

    test_loader = DataLoader(
        test_dataset,
        batch_size=Config.batch_size * 4,
        shuffle=False,
        num_workers=0
    )

    # åŠ è½½æ‰€æœ‰è®­ç»ƒå¥½çš„æ¨¡å‹
    model_files = []
    for f in os.listdir(Config.model_save_path):
        if f.startswith('best_') and f.endswith('.pth'):
            model_files.append(f)

    if not model_files:
        print("æœªæ‰¾åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹")
        return None

    print(f"æ‰¾åˆ° {len(model_files)} ä¸ªæ¨¡å‹ç”¨äºé›†æˆ")

    # æ”¶é›†æ‰€æœ‰æ¨¡å‹çš„é¢„æµ‹
    all_predictions = []

    for model_file in model_files:
        print(f"\nåŠ è½½æ¨¡å‹: {model_file}")

        checkpoint = torch.load(
            os.path.join(Config.model_save_path, model_file),
            map_location=Config.device
        )

        # è·å–æ¨¡å‹åç§°
        model_name = checkpoint.get('model_name', 'resnet34')

        # åˆ›å»ºæ¨¡å‹
        try:
            model = AttentionEmotionModel(model_name, Config.num_classes, pretrained=False)
        except:
            # å¦‚æœåˆ›å»ºå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡å‹
            model = AttentionEmotionModel('resnet34', Config.num_classes, pretrained=False)

        model.load_state_dict(checkpoint['model_state_dict'])
        model = model.to(Config.device)
        model.eval()

        # è¿›è¡Œé¢„æµ‹
        predictions = []
        with torch.no_grad():
            for inputs, _, _ in test_loader:
                inputs = inputs.to(Config.device)
                outputs = model(inputs)

                # ä½¿ç”¨softmaxè·å–æ¦‚ç‡
                probs = torch.softmax(outputs, dim=1)
                _, preds = probs.max(1)
                predictions.extend(preds.cpu().numpy())

        all_predictions.append(predictions)
        print(f"  å®Œæˆé¢„æµ‹")

    # é›†æˆé¢„æµ‹ï¼ˆæŠ•ç¥¨ï¼‰
    print("\nè¿›è¡Œé›†æˆæŠ•ç¥¨...")
    all_predictions = np.array(all_predictions)
    final_predictions = []

    for i in range(len(test_ids)):
        votes = all_predictions[:, i]
        # å¤šæ•°æŠ•ç¥¨
        final_predictions.append(np.bincount(votes).argmax())

    # åˆ›å»ºæäº¤æ–‡ä»¶
    submission_df = pd.DataFrame({
        'ID': test_ids,
        'Emotion': final_predictions
    })

    # æ’åºå¹¶ä¿å­˜
    submission_df = submission_df.sort_values('ID').reset_index(drop=True)
    submission_df.to_csv(Config.submission_file, index=False)

    print(f"\nâœ“ æäº¤æ–‡ä»¶å·²ä¿å­˜: {Config.submission_file}")
    print(f"  æ€»é¢„æµ‹æ•°: {len(submission_df)}")

    # æ˜¾ç¤ºé¢„æµ‹åˆ†å¸ƒ
    print("\né¢„æµ‹åˆ†å¸ƒ:")
    emotion_counts = submission_df['Emotion'].value_counts().sort_index()
    for emotion_id, emotion_name in Config.emotion_map.items():
        count = emotion_counts.get(emotion_id, 0)
        percentage = count / len(submission_df) * 100
        print(f"  {emotion_name}: {count} ({percentage:.1f}%)")

    return submission_df


# ==================== 8. ä¸»å‡½æ•° ====================
def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("äººè„¸æƒ…æ„Ÿåˆ†ç±» - ç»ˆæé«˜å‡†ç¡®ç‡ç‰ˆæœ¬")
    print(f"ç›®æ ‡: 85%+ å‡†ç¡®ç‡")
    print(f"è®¾å¤‡: {Config.device}")
    print(f"å›¾åƒå°ºå¯¸: {Config.img_size}x{Config.img_size}")
    print("=" * 80)

    # æ£€æŸ¥æ•°æ®
    if not os.path.exists(Config.train_dir):
        print(f"\né”™è¯¯: è®­ç»ƒç›®å½• '{Config.train_dir}' ä¸å­˜åœ¨!")
        print("è¯·ç¡®ä¿æ•°æ®æŒ‰ä»¥ä¸‹ç»“æ„ç»„ç»‡:")
        print("  ./train/Angry/      # åŒ…å«æ„¤æ€’è¡¨æƒ…å›¾åƒ")
        print("  ./train/Fear/       # åŒ…å«ææƒ§è¡¨æƒ…å›¾åƒ")
        print("  ./train/Happy/      # åŒ…å«å¿«ä¹è¡¨æƒ…å›¾åƒ")
        print("  ./train/Sad/        # åŒ…å«æ‚²ä¼¤è¡¨æƒ…å›¾åƒ")
        print("  ./train/Surprise/   # åŒ…å«æƒŠè®¶è¡¨æƒ…å›¾åƒ")
        print("  ./train/Neutral/    # åŒ…å«ä¸­æ€§è¡¨æƒ…å›¾åƒ")
        return

    start_time = time.time()

    # è‡ªåŠ¨è®­ç»ƒæµç¨‹
    print("\n" + "=" * 80)
    print("å¼€å§‹è‡ªåŠ¨è®­ç»ƒæµç¨‹")
    print("=" * 80)

    # é€‰æ‹©è®­ç»ƒæ¨¡å¼
    if Config.use_ensemble:
        print("\nä½¿ç”¨é›†æˆå­¦ä¹ æ¨¡å¼ (è®­ç»ƒå¤šä¸ªæ¨¡å‹)")
        print(f"å°†è®­ç»ƒä»¥ä¸‹æ¨¡å‹: {', '.join(Config.model_names[:Config.n_models])}")

        # è®­ç»ƒé›†æˆæ¨¡å‹
        avg_acc = ensemble_training()

        print(f"\né›†æˆå­¦ä¹ å¹³å‡å‡†ç¡®ç‡: {avg_acc:.2f}%")

        if avg_acc < 75:
            print("\nâš ï¸  å‡†ç¡®ç‡è¿˜æœ‰æå‡ç©ºé—´ï¼Œå»ºè®®:")
            print("  1. å¢åŠ è®­ç»ƒè½®æ¬¡ (ä¿®æ”¹ Config.epochs = 50)")
            print("  2. ä½¿ç”¨æ›´å¤§çš„å›¾åƒå°ºå¯¸ (ä¿®æ”¹ Config.img_size = 112)")
            print("  3. æ·»åŠ æ›´å¤šæ•°æ®å¢å¼º")
        elif avg_acc < 85:
            print("\nâœ… å‡†ç¡®ç‡è‰¯å¥½ï¼Œå¯ä»¥å°è¯•:")
            print("  1. ä½¿ç”¨æ›´å¤šæ¨¡å‹è¿›è¡Œé›†æˆ")
            print("  2. å°è¯•æ›´å¤æ‚çš„æ¨¡å‹æ¶æ„")
        else:
            print("\nğŸ‰ å‡†ç¡®ç‡ä¼˜ç§€! å·²è¾¾åˆ°ç›®æ ‡")

    else:
        print("\nä½¿ç”¨äº¤å‰éªŒè¯æ¨¡å¼")
        mean_acc = cross_validation_training()
        print(f"\näº¤å‰éªŒè¯å¹³å‡å‡†ç¡®ç‡: {mean_acc:.2f}%")

    # é¢„æµ‹æµ‹è¯•é›†
    if os.path.exists(Config.test_dir):
        print("\n" + "=" * 80)
        print("å¼€å§‹é¢„æµ‹æµ‹è¯•é›†")
        print("=" * 80)

        submission = ensemble_predict()

        if submission is not None:
            print("\n" + "=" * 80)
            print("æäº¤å‡†å¤‡å°±ç»ª!")
            print("=" * 80)
            print(f"æ–‡ä»¶: {Config.submission_file}")
            print("æ ¼å¼: CSVæ–‡ä»¶ï¼ŒåŒ…å«ä¸¤åˆ—: ID, Emotion")
            print("\nå°†æ­¤æ–‡ä»¶ä¸Šä¼ è‡³è¯„æµ‹å¹³å°")
    else:
        print(f"\næµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {Config.test_dir}")
        print("æ¨¡å‹å·²ä¿å­˜ï¼Œå¯åœ¨æœ‰æµ‹è¯•æ•°æ®æ—¶è¿›è¡Œé¢„æµ‹")

    # æ—¶é—´ç»Ÿè®¡
    total_time = time.time() - start_time
    hours = total_time // 3600
    minutes = (total_time % 3600) // 60
    seconds = total_time % 60

    print(f"\næ€»è€—æ—¶: {hours:.0f}å°æ—¶ {minutes:.0f}åˆ†é’Ÿ {seconds:.0f}ç§’")
    print("\n" + "=" * 80)
    print("ç¨‹åºå®Œæˆ!")
    print("=" * 80)


# ==================== 9. è¿è¡Œç¨‹åº ====================
if __name__ == "__main__":
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(42)

    # è¿è¡Œä¸»ç¨‹åº
    try:
        main()
    except Exception as e:
        print(f"\nç¨‹åºå‡ºé”™: {e}")
        import traceback

        traceback.print_exc()

        # æä¾›ç®€åŒ–çš„å¤‡é€‰æ–¹æ¡ˆ
        print("\n" + "=" * 80)
        print("å¦‚æœä¸Šè¿°æ–¹æ¡ˆæœ‰é—®é¢˜ï¼Œè¯·å°è¯•ä»¥ä¸‹ç®€åŒ–ç‰ˆæœ¬:")
        print("1. å°† Config.img_size æ”¹ä¸º 64")
        print("2. å°† Config.model_names æ”¹ä¸º ['resnet18']")
        print("3. å°† Config.epochs æ”¹ä¸º 30")

        print("=" * 80)
