import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, WeightedRandomSampler
from torchvision import transforms, datasets, models
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
from PIL import Image
import warnings
from sklearn.model_selection import KFold
from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR

warnings.filterwarnings('ignore')

print("=" * 60)
print("ğŸŒ± æ¤ç‰©å¹¼è‹—åˆ†ç±»ç³»ç»Ÿ - é«˜çº§ä¼˜åŒ–ç‰ˆ")
print("=" * 60)

# é…ç½®è®¾ç½®
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = BASE_DIR
TRAIN_DIR = os.path.join(DATA_DIR, 'train')
TEST_DIR = os.path.join(DATA_DIR, 'test')
OUTPUT_DIR = os.path.join(BASE_DIR, 'outputs')
os.makedirs(OUTPUT_DIR, exist_ok=True)

# è®¾ç½®è®¾å¤‡
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# 1. æ•°æ®å¢å¼ºå¼ºåŒ–
train_transform = transforms.Compose([
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.2),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),
    transforms.RandomErasing(p=0.2, scale=(0.02, 0.1))
])

val_transform = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])


# 2. æ›´å¼ºå¤§çš„æ¨¡å‹ï¼ˆResNet50æˆ–EfficientNetï¼‰
class PlantClassifier(nn.Module):
    def __init__(self, num_classes, model_name='resnet50'):
        super(PlantClassifier, self).__init__()
        if model_name == 'resnet50':
            self.backbone = models.resnet50(pretrained=True)
            in_features = self.backbone.fc.in_features
            self.backbone.fc = nn.Identity()
        elif model_name == 'efficientnet':
            self.backbone = models.efficientnet_b3(pretrained=True)
            in_features = self.backbone.classifier[1].in_features
            self.backbone.classifier = nn.Identity()
        else:
            self.backbone = models.resnet34(pretrained=True)
            in_features = self.backbone.fc.in_features
            self.backbone.fc = nn.Identity()

        # æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶
        self.attention = nn.Sequential(
            nn.Linear(in_features, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, in_features),
            nn.Sigmoid()
        )

        self.classifier = nn.Sequential(
            nn.Dropout(0.5),
            nn.Linear(in_features, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, num_classes)
        )

    def forward(self, x):
        features = self.backbone(x)
        attention_weights = self.attention(features)
        attended_features = features * attention_weights
        return self.classifier(attended_features)


# 3. å¤„ç†ç±»åˆ«ä¸å¹³è¡¡
def get_class_weights(train_dir):
    class_counts = []
    class_names = sorted([d for d in os.listdir(train_dir)
                          if os.path.isdir(os.path.join(train_dir, d))])

    for class_name in class_names:
        class_path = os.path.join(train_dir, class_name)
        img_count = len([f for f in os.listdir(class_path) if f.endswith('.png')])
        class_counts.append(img_count)

    total_samples = sum(class_counts)
    weights = [total_samples / count for count in class_counts]
    weights = torch.FloatTensor(weights).to(device)
    return weights


# 4. è®­ç»ƒå‡½æ•°ä¼˜åŒ–
def train_epoch(model, loader, criterion, optimizer, device):
    model.train()
    total_loss = 0.0
    correct = 0
    total = 0

    for images, labels in tqdm(loader, desc='è®­ç»ƒ'):
        images, labels = images.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels)

        # æ·»åŠ L2æ­£åˆ™åŒ–
        l2_lambda = 0.001
        l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())
        loss = loss + l2_lambda * l2_norm

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # æ¢¯åº¦è£å‰ª
        optimizer.step()

        total_loss += loss.item()
        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    return total_loss / len(loader), 100.0 * correct / total


def validate(model, loader, criterion, device):
    model.eval()
    total_loss = 0.0
    correct = 0
    total = 0
    all_preds = []
    all_labels = []

    with torch.no_grad():
        for images, labels in tqdm(loader, desc='éªŒè¯'):
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)

            total_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

            all_preds.extend(predicted.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    return total_loss / len(loader), 100.0 * correct / total, all_preds, all_labels


# 5. TTAï¼ˆæµ‹è¯•æ—¶å¢å¼ºï¼‰
def predict_with_tta(model, image_path, transform, device, tta_transforms=None):
    if tta_transforms is None:
        tta_transforms = [
            transforms.Compose([
                transforms.Resize(256),
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
            transforms.Compose([
                transforms.Resize(256),
                transforms.RandomCrop(224),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ]),
            transforms.Compose([
                transforms.Resize(256),
                transforms.CenterCrop(224),
                transforms.RandomHorizontalFlip(p=1.0),
                transforms.ToTensor(),
                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
            ])
        ]

    model.eval()
    predictions = []

    for tta_transform in tta_transforms:
        try:
            image = Image.open(image_path).convert('RGB')
            image_tensor = tta_transform(image).unsqueeze(0).to(device)

            with torch.no_grad():
                outputs = model(image_tensor)
                predictions.append(outputs.cpu().numpy())
        except:
            continue

    if predictions:
        avg_pred = np.mean(predictions, axis=0)
        predicted_idx = np.argmax(avg_pred)
    else:
        predicted_idx = 0

    return predicted_idx


def main():
    # æ£€æŸ¥æ•°æ®ç›®å½•
    print(f"\n[1/5] æ£€æŸ¥æ•°æ®ç›®å½•...")
    if not os.path.exists(TRAIN_DIR):
        print(f"âŒ è®­ç»ƒç›®å½•ä¸å­˜åœ¨: {TRAIN_DIR}")
        return

    class_names = sorted([d for d in os.listdir(TRAIN_DIR)
                          if os.path.isdir(os.path.join(TRAIN_DIR, d))])
    print(f"âœ… æ‰¾åˆ° {len(class_names)} ä¸ªç±»åˆ«")

    # åŠ è½½å®Œæ•´æ•°æ®é›†
    print(f"\n[2/5] å‡†å¤‡æ•°æ®...")
    full_dataset = datasets.ImageFolder(TRAIN_DIR, transform=train_transform)

    # ä½¿ç”¨KFoldäº¤å‰éªŒè¯
    kfold = KFold(n_splits=5, shuffle=True, random_state=42)
    all_indices = list(range(len(full_dataset)))

    fold_results = []
    best_models = []

    for fold, (train_idx, val_idx) in enumerate(kfold.split(all_indices)):
        print(f"\n{'=' * 40}")
        print(f"è®­ç»ƒ Fold {fold + 1}/5")
        print(f"{'=' * 40}")

        train_subsampler = torch.utils.data.SubsetRandomSampler(train_idx)
        val_subsampler = torch.utils.data.SubsetRandomSampler(val_idx)

        train_loader = DataLoader(full_dataset, batch_size=32, sampler=train_subsampler, num_workers=2)
        val_loader = DataLoader(full_dataset, batch_size=32, sampler=val_subsampler, num_workers=2)

        # åˆ›å»ºæ¨¡å‹
        model = PlantClassifier(num_classes=len(class_names), model_name='resnet50')
        model = model.to(device)

        # ç±»åˆ«æƒé‡
        class_weights = get_class_weights(TRAIN_DIR)
        criterion = nn.CrossEntropyLoss(weight=class_weights)

        # ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡è°ƒåº¦
        optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.01)
        scheduler = CosineAnnealingLR(optimizer, T_max=20, eta_min=1e-6)

        best_val_acc = 0.0
        patience = 10
        patience_counter = 0

        # è®­ç»ƒå¾ªç¯
        for epoch in range(30):  # å¢åŠ epoch
            print(f"\nEpoch {epoch + 1}/30")

            # è®­ç»ƒ
            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)

            # éªŒè¯
            val_loss, val_acc, _, _ = validate(model, val_loader, criterion, device)

            print(f"è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.2f}%")
            print(f"éªŒè¯æŸå¤±: {val_loss:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.2f}%")

            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step()

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
                model_path = os.path.join(OUTPUT_DIR, f'best_model_fold{fold + 1}.pth')
                torch.save({
                    'model_state_dict': model.state_dict(),
                    'val_acc': val_acc,
                    'epoch': epoch
                }, model_path)
                print(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ (Fold {fold + 1}): {val_acc:.2f}%")
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    print(f"æ—©åœè§¦å‘ (Fold {fold + 1})")
                    break

        fold_results.append(best_val_acc)
        best_models.append(model)
        print(f"Fold {fold + 1} å®Œæˆ - æœ€ä½³å‡†ç¡®ç‡: {best_val_acc:.2f}%")

    print(f"\näº¤å‰éªŒè¯ç»“æœ: {fold_results}")
    print(f"å¹³å‡å‡†ç¡®ç‡: {np.mean(fold_results):.2f}% Â± {np.std(fold_results):.2f}%")

    # 6. æ¨¡å‹é›†æˆ
    print(f"\n[3/5] æ¨¡å‹é›†æˆ...")

    def ensemble_predict(models, image_tensor):
        all_preds = []
        for model in models:
            model.eval()
            with torch.no_grad():
                outputs = model(image_tensor.to(device))
                probs = torch.softmax(outputs, dim=1)
                all_preds.append(probs.cpu().numpy())

        avg_probs = np.mean(all_preds, axis=0)
        return np.argmax(avg_probs, axis=1)

    # é¢„æµ‹æµ‹è¯•é›†
    print(f"\n[4/5] é¢„æµ‹æµ‹è¯•é›†...")

    if not os.path.exists(TEST_DIR):
        print(f"âš ï¸ æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {TEST_DIR}")
        return

    test_images = [f for f in os.listdir(TEST_DIR) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    if not test_images:
        print("âš ï¸ æµ‹è¯•ç›®å½•ä¸­æ²¡æœ‰å›¾åƒæ–‡ä»¶")
        return

    print(f"âœ… æ‰¾åˆ° {len(test_images)} å¼ æµ‹è¯•å›¾åƒ")

    predictions = []

    for img_name in tqdm(test_images, desc='é¢„æµ‹'):
        try:
            img_path = os.path.join(TEST_DIR, img_name)

            # ä½¿ç”¨TTAå’Œæ¨¡å‹é›†æˆ
            image = Image.open(img_path).convert('RGB')
            image_tensor = val_transform(image).unsqueeze(0)

            # é›†æˆé¢„æµ‹
            predicted_idx = ensemble_predict(best_models, image_tensor)[0]
            predicted_class = class_names[predicted_idx]

            predictions.append({
                'image_name': img_name,
                'species': predicted_class
            })

        except Exception as e:
            print(f"âš ï¸ å¤„ç†å›¾åƒ {img_name} æ—¶å‡ºé”™: {e}")
            predictions.append({
                'image_name': img_name,
                'species': class_names[0] if class_names else 'Unknown'
            })

    # 7. ä¿å­˜ç»“æœ
    print(f"\n[5/5] ä¿å­˜ç»“æœ...")

    submission_path = os.path.join(OUTPUT_DIR, 'submission_ensemble.csv')
    df = pd.DataFrame(predictions)
    df.to_csv(submission_path, index=False)

    print(f"âœ… æäº¤æ–‡ä»¶å·²ä¿å­˜: {submission_path}")

    # åˆ†æç»“æœ
    print(f"\nğŸ“Š é¢„æµ‹ç»“æœåˆ†å¸ƒ:")
    species_counts = df['species'].value_counts()
    for species, count in species_counts.items():
        percentage = count / len(df) * 100
        print(f"  {species}: {count} å¼  ({percentage:.1f}%)")

    print("\nğŸ¯ ä¼˜åŒ–ç­–ç•¥æ€»ç»“:")
    print("  1. ä½¿ç”¨ResNet50/EfficientNetç­‰æ›´å¼ºæ¨¡å‹")
    print("  2. æ·»åŠ æ³¨æ„åŠ›æœºåˆ¶å’Œæ›´æ·±åˆ†ç±»å¤´")
    print("  3. 5æŠ˜äº¤å‰éªŒè¯")
    print("  4. æ¨¡å‹é›†æˆ")
    print("  5. æ›´å¼ºçš„æ•°æ®å¢å¼º")
    print("  6. ç±»åˆ«æƒé‡å¤„ç†ä¸å¹³è¡¡")
    print("  7. TTAï¼ˆæµ‹è¯•æ—¶å¢å¼ºï¼‰")
    print("  8. å­¦ä¹ ç‡è°ƒåº¦å’Œæ—©åœ")
    print(f"\né¢„æœŸå‡†ç¡®ç‡: 0.90+")


if __name__ == "__main__":
    main()

